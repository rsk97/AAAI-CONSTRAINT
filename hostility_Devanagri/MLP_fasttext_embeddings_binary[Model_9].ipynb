{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combine meta data with text in keras'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/combining-numerical-and-text-features-in-deep-neural-networks-e91f0237eea4\n",
    "\"\"\"combine meta data with text in keras\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "ft = fasttext.load_model(embedding_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import gensim\n",
    "nlp = spacy.load('en')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import demoji\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "import wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>Post</th>\n",
       "      <th>Labels Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...</td>\n",
       "      <td>hate,offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>सरकार हमेशा से किसानों की कमाई को बढ़ाने के लि...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>सुशांत ने जो बिजनेस डील 9 जून को की थी, वो डील...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...</td>\n",
       "      <td>defamation,offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>#unlock4guidelines - अनलॉक-4 के लिए गाइडलाइन्स...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique ID                                               Post  \\\n",
       "0          1  मेरे देश के हिन्दु बहुत निराले है। कुछ तो पक्क...   \n",
       "1          2  सरकार हमेशा से किसानों की कमाई को बढ़ाने के लि...   \n",
       "2          3  सुशांत ने जो बिजनेस डील 9 जून को की थी, वो डील...   \n",
       "3          4  @prabhav218 साले जेएनयू छाप कमिने लोग हिन्दुओं...   \n",
       "4          5  #unlock4guidelines - अनलॉक-4 के लिए गाइडलाइन्स...   \n",
       "\n",
       "             Labels Set  \n",
       "0        hate,offensive  \n",
       "1           non-hostile  \n",
       "2           non-hostile  \n",
       "3  defamation,offensive  \n",
       "4           non-hostile  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/ayush/Documents/personal/research/aaai/hostility_classification/data/constraint_Hindi_Train - Sheet1.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making labels\n",
    "from keras.utils import to_categorical\n",
    "y = []\n",
    "label_mapping = {'non-hostile':0, 'hate':1,'offensive':1,'fake':1,'defamation':1}\n",
    "for labels in data['Labels Set']:\n",
    "    temp = list(set([str(i)for i in [label_mapping[x] for x in labels.split(',')]]))\n",
    "    temp = \" \".join(temp)\n",
    "    #print(temp)\n",
    "    y.append(temp)\n",
    "y = [int(x) for x in y]\n",
    "y = to_categorical(y)\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_stop_words = [\"अंदर\",\"अत\",\"अदि\",\"अप\",\"अपना\",\"अपनि\",\"अपनी\",\"अपने\",\"अभि\",\"अभी\",\"आदि\",\"आप\",\"इंहिं\",\"इंहें\",\"इंहों\",\"इतयादि\",\"इत्यादि\",\"इन\",\"इनका\",\"इन्हीं\",\"इन्हें\",\"इन्हों\",\"इस\",\"इसका\",\"इसकि\",\"इसकी\",\"इसके\",\"इसमें\",\"इसि\",\"इसी\",\"इसे\",\"उंहिं\",\"उंहें\",\"उंहों\",\"उन\",\"उनका\",\"उनकि\",\"उनकी\",\"उनके\",\"उनको\",\"उन्हीं\",\"उन्हें\",\"उन्हों\",\"उस\",\"उसके\",\"उसि\",\"उसी\",\"उसे\",\"एक\",\"एवं\",\"एस\",\"एसे\",\"ऐसे\",\"ओर\",\"और\",\"कइ\",\"कई\",\"कर\",\"करता\",\"करते\",\"करना\",\"करने\",\"करें\",\"कहते\",\"कहा\",\"का\",\"काफि\",\"काफ़ी\",\"कि\",\"किंहें\",\"किंहों\",\"कितना\",\"किन्हें\",\"किन्हों\",\"किया\",\"किर\",\"किस\",\"किसि\",\"किसी\",\"किसे\",\"की\",\"कुछ\",\"कुल\",\"के\",\"को\",\"कोइ\",\"कोई\",\"कोन\",\"कोनसा\",\"कौन\",\"कौनसा\",\"गया\",\"घर\",\"जब\",\"जहाँ\",\"जहां\",\"जा\",\"जिंहें\",\"जिंहों\",\"जितना\",\"जिधर\",\"जिन\",\"जिन्हें\",\"जिन्हों\",\"जिस\",\"जिसे\",\"जीधर\",\"जेसा\",\"जेसे\",\"जैसा\",\"जैसे\",\"जो\",\"तक\",\"तब\",\"तरह\",\"तिंहें\",\"तिंहों\",\"तिन\",\"तिन्हें\",\"तिन्हों\",\"तिस\",\"तिसे\",\"तो\",\"था\",\"थि\",\"थी\",\"थे\",\"दबारा\",\"दवारा\",\"दिया\",\"दुसरा\",\"दुसरे\",\"दूसरे\",\"दो\",\"द्वारा\",\"न\",\"नहिं\",\"नहीं\",\"ना\",\"निचे\",\"निहायत\",\"नीचे\",\"ने\",\"पर\",\"पहले\",\"पुरा\",\"पूरा\",\"पे\",\"फिर\",\"बनि\",\"बनी\",\"बहि\",\"बही\",\"बहुत\",\"बाद\",\"बाला\",\"बिलकुल\",\"भि\",\"भितर\",\"भी\",\"भीतर\",\"मगर\",\"मानो\",\"मे\",\"में\",\"यदि\",\"यह\",\"यहाँ\",\"यहां\",\"यहि\",\"यही\",\"या\",\"यिह\",\"ये\",\"रखें\",\"रवासा\",\"रहा\",\"रहे\",\"ऱ्वासा\",\"लिए\",\"लिये\",\"लेकिन\",\"व\",\"वगेरह\",\"वरग\",\"वर्ग\",\"वह\",\"वहाँ\",\"वहां\",\"वहिं\",\"वहीं\",\"वाले\",\"वुह\",\"वे\",\"वग़ैरह\",\"संग\",\"सकता\",\"सकते\",\"सबसे\",\"सभि\",\"सभी\",\"साथ\",\"साबुत\",\"साभ\",\"सारा\",\"से\",\"सो\",\"हि\",\"ही\",\"हुअ\",\"हुआ\",\"हुइ\",\"हुई\",\"हुए\",\"हे\",\"हें\",\"है\",\"हैं\",\"हो\",\"होता\",\"होति\",\"होती\",\"होते\",\"होना\",\"होने\"]\n",
    "len(hindi_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_analysis(tweet):\n",
    "    # url\n",
    "    urls = re.findall(r\"(?:https?\\://)\\S+\", tweet)\n",
    "    ## remove url from tweet\n",
    "    tweet = re.sub(r\"(?:https?\\://)\\S+\", \"\", tweet)\n",
    "    \n",
    "    #cleaning \n",
    "    pat = re.compile(r\"([',./(;_`:|\\-)!])\")\n",
    "    tweet = pat.sub(\"\", tweet)\n",
    "    tweet = tweet.rstrip(\"\\n\")\n",
    "    tweet = re.sub('\\n', ' ', tweet)\n",
    "    tweet = tweet.replace('\\u200b', '')\n",
    "    tweet = tweet.replace('\\u200c', '')\n",
    "    tweet = tweet.replace('\\u200d', '')\n",
    "    \n",
    "    # hashtag\n",
    "    hashtag_words = re.findall(r'#([^\\s]+)', tweet)\n",
    "    ## remove hashtag\n",
    "    tweet = re.sub(r'#([^\\s]+)', \"\", tweet)\n",
    "    \n",
    "    #mentions\n",
    "    mention_words = re.findall(r'@([^\\s]+)', tweet)\n",
    "    ## remove mentions\n",
    "    tweet = re.sub(r'@([^\\s]+)', '', tweet)\n",
    "    \n",
    "    #print(translator.translate('Jankari', dest='hi').text)\n",
    "    # english words\n",
    "    english_words = [word for word in tweet.split() if re.search(r'[a-zA-Z]', word)]\n",
    "    ## remove english words\n",
    "    tweet = \" \".join([word for word in tweet.split() if word not in english_words])\n",
    "    #tweet = \" \".join([word if word not in english_words else translator.translate(\" \".join(wordninja.split(word)), dest='hi').text for word in tweet.split()])\n",
    "    #f(x) if condition else g(x) for x in sequence\n",
    "    emojis = demoji.findall_list(tweet, desc = True)\n",
    "    tweet = demoji.replace(tweet,\"\")\n",
    "    tweet = \" \".join([word for word in tweet.split() if word not in hindi_stop_words])\n",
    "    return tweet, urls, hashtag_words, mention_words, english_words, emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5728/5728 [00:07<00:00, 782.00it/s]\n"
     ]
    }
   ],
   "source": [
    "all_tweets= []\n",
    "for tweet in tqdm(data['Post']):\n",
    "    all_tweets.append(feature_analysis(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_loc = \"/home/ayush/Documents/personal/research/aaai/hostility_classification/fastText/cc.hi.300.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for tweet in all_tweets:\n",
    "    X.append(ft.get_sentence_vector(tweet[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 300)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=X)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df[:5500]\n",
    "# y_train = y[:5500]\n",
    "\n",
    "# X_test = df[5500:]\n",
    "# y_test = y[5500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5670, 2)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_length, 20, input_length= 300))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "my_callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=5,\n",
    "                              verbose=1, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "opt = tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.01, momentum=0.1, nesterov=True, name=\"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input2 = Input(shape=(300,))\n",
    "dense_layer_1 = Dense(100, activation='relu')(input2)\n",
    "dense_layer_2 = Dense(100, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(100, activation='relu')(dense_layer_2)\n",
    "output = Dense(2, activation='sigmoid')(dense_layer_3)\n",
    "\n",
    "model = Model(inputs=input2, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc',f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/170\n",
      "284/284 - 0s - loss: 0.6913 - acc: 0.5353 - f1_m: 0.4826 - val_loss: 0.6920 - val_acc: 0.5088 - val_f1_m: 0.5088\n",
      "Epoch 2/170\n",
      "284/284 - 0s - loss: 0.6887 - acc: 0.5386 - f1_m: 0.5392 - val_loss: 0.6906 - val_acc: 0.5088 - val_f1_m: 0.5088\n",
      "Epoch 3/170\n",
      "284/284 - 0s - loss: 0.6867 - acc: 0.5386 - f1_m: 0.5383 - val_loss: 0.6892 - val_acc: 0.5088 - val_f1_m: 0.5088\n",
      "Epoch 4/170\n",
      "284/284 - 0s - loss: 0.6848 - acc: 0.5386 - f1_m: 0.5385 - val_loss: 0.6878 - val_acc: 0.5088 - val_f1_m: 0.5088\n",
      "Epoch 5/170\n",
      "284/284 - 0s - loss: 0.6827 - acc: 0.5386 - f1_m: 0.5385 - val_loss: 0.6856 - val_acc: 0.5088 - val_f1_m: 0.5088\n",
      "Epoch 6/170\n",
      "284/284 - 0s - loss: 0.6802 - acc: 0.5386 - f1_m: 0.5390 - val_loss: 0.6828 - val_acc: 0.5088 - val_f1_m: 0.5088\n",
      "Epoch 7/170\n",
      "284/284 - 0s - loss: 0.6770 - acc: 0.5386 - f1_m: 0.5391 - val_loss: 0.6783 - val_acc: 0.5088 - val_f1_m: 0.5146\n",
      "Epoch 8/170\n",
      "284/284 - 0s - loss: 0.6729 - acc: 0.5401 - f1_m: 0.5428 - val_loss: 0.6731 - val_acc: 0.5414 - val_f1_m: 0.5504\n",
      "Epoch 9/170\n",
      "284/284 - 0s - loss: 0.6672 - acc: 0.5728 - f1_m: 0.5806 - val_loss: 0.6678 - val_acc: 0.5406 - val_f1_m: 0.5436\n",
      "Epoch 10/170\n",
      "284/284 - 0s - loss: 0.6594 - acc: 0.6127 - f1_m: 0.6206 - val_loss: 0.6577 - val_acc: 0.6093 - val_f1_m: 0.6223\n",
      "Epoch 11/170\n",
      "284/284 - 0s - loss: 0.6482 - acc: 0.6770 - f1_m: 0.6827 - val_loss: 0.6454 - val_acc: 0.6429 - val_f1_m: 0.6496\n",
      "Epoch 12/170\n",
      "284/284 - 0s - loss: 0.6327 - acc: 0.7088 - f1_m: 0.7129 - val_loss: 0.6253 - val_acc: 0.7134 - val_f1_m: 0.7201\n",
      "Epoch 13/170\n",
      "284/284 - 0s - loss: 0.6105 - acc: 0.7438 - f1_m: 0.7438 - val_loss: 0.5984 - val_acc: 0.7972 - val_f1_m: 0.7984\n",
      "Epoch 14/170\n",
      "284/284 - 0s - loss: 0.5818 - acc: 0.7720 - f1_m: 0.7719 - val_loss: 0.5634 - val_acc: 0.7998 - val_f1_m: 0.7999\n",
      "Epoch 15/170\n",
      "284/284 - 0s - loss: 0.5479 - acc: 0.7809 - f1_m: 0.7805 - val_loss: 0.5265 - val_acc: 0.8034 - val_f1_m: 0.8046\n",
      "Epoch 16/170\n",
      "284/284 - 0s - loss: 0.5124 - acc: 0.7853 - f1_m: 0.7853 - val_loss: 0.4961 - val_acc: 0.8034 - val_f1_m: 0.8026\n",
      "Epoch 17/170\n",
      "284/284 - 0s - loss: 0.4829 - acc: 0.7879 - f1_m: 0.7883 - val_loss: 0.4639 - val_acc: 0.8042 - val_f1_m: 0.8045\n",
      "Epoch 18/170\n",
      "284/284 - 0s - loss: 0.4610 - acc: 0.7937 - f1_m: 0.7943 - val_loss: 0.4451 - val_acc: 0.8095 - val_f1_m: 0.8096\n",
      "Epoch 19/170\n",
      "284/284 - 0s - loss: 0.4448 - acc: 0.7998 - f1_m: 0.8006 - val_loss: 0.4378 - val_acc: 0.8139 - val_f1_m: 0.8139\n",
      "Epoch 20/170\n",
      "284/284 - 0s - loss: 0.4329 - acc: 0.8086 - f1_m: 0.8077 - val_loss: 0.4508 - val_acc: 0.7981 - val_f1_m: 0.7971\n",
      "Epoch 21/170\n",
      "284/284 - 0s - loss: 0.4235 - acc: 0.8111 - f1_m: 0.8110 - val_loss: 0.4110 - val_acc: 0.8236 - val_f1_m: 0.8236\n",
      "Epoch 22/170\n",
      "284/284 - 0s - loss: 0.4152 - acc: 0.8108 - f1_m: 0.8107 - val_loss: 0.4010 - val_acc: 0.8201 - val_f1_m: 0.8209\n",
      "Epoch 23/170\n",
      "284/284 - 0s - loss: 0.4038 - acc: 0.8170 - f1_m: 0.8175 - val_loss: 0.3940 - val_acc: 0.8236 - val_f1_m: 0.8235\n",
      "Epoch 24/170\n",
      "284/284 - 0s - loss: 0.4019 - acc: 0.8186 - f1_m: 0.8183 - val_loss: 0.4010 - val_acc: 0.8245 - val_f1_m: 0.8243\n",
      "Epoch 25/170\n",
      "284/284 - 0s - loss: 0.3928 - acc: 0.8261 - f1_m: 0.8258 - val_loss: 0.3947 - val_acc: 0.8263 - val_f1_m: 0.8257\n",
      "Epoch 26/170\n",
      "284/284 - 0s - loss: 0.3896 - acc: 0.8291 - f1_m: 0.8295 - val_loss: 0.3845 - val_acc: 0.8342 - val_f1_m: 0.8341\n",
      "Epoch 27/170\n",
      "284/284 - 0s - loss: 0.3832 - acc: 0.8296 - f1_m: 0.8298 - val_loss: 0.3772 - val_acc: 0.8413 - val_f1_m: 0.8412\n",
      "Epoch 28/170\n",
      "284/284 - 0s - loss: 0.3770 - acc: 0.8309 - f1_m: 0.8314 - val_loss: 0.3704 - val_acc: 0.8413 - val_f1_m: 0.8414\n",
      "Epoch 29/170\n",
      "284/284 - 0s - loss: 0.3762 - acc: 0.8313 - f1_m: 0.8311 - val_loss: 0.3651 - val_acc: 0.8457 - val_f1_m: 0.8457\n",
      "Epoch 30/170\n",
      "284/284 - 0s - loss: 0.3715 - acc: 0.8349 - f1_m: 0.8346 - val_loss: 0.4007 - val_acc: 0.8228 - val_f1_m: 0.8216\n",
      "Epoch 31/170\n",
      "284/284 - 0s - loss: 0.3667 - acc: 0.8397 - f1_m: 0.8389 - val_loss: 0.3584 - val_acc: 0.8430 - val_f1_m: 0.8425\n",
      "Epoch 32/170\n",
      "284/284 - 0s - loss: 0.3640 - acc: 0.8446 - f1_m: 0.8442 - val_loss: 0.3914 - val_acc: 0.8272 - val_f1_m: 0.8270\n",
      "Epoch 33/170\n",
      "284/284 - 0s - loss: 0.3616 - acc: 0.8437 - f1_m: 0.8430 - val_loss: 0.3542 - val_acc: 0.8457 - val_f1_m: 0.8450\n",
      "Epoch 34/170\n",
      "284/284 - 0s - loss: 0.3576 - acc: 0.8424 - f1_m: 0.8420 - val_loss: 0.3595 - val_acc: 0.8554 - val_f1_m: 0.8557\n",
      "Epoch 35/170\n",
      "284/284 - 0s - loss: 0.3562 - acc: 0.8437 - f1_m: 0.8438 - val_loss: 0.3666 - val_acc: 0.8377 - val_f1_m: 0.8378\n",
      "Epoch 36/170\n",
      "284/284 - 0s - loss: 0.3579 - acc: 0.8397 - f1_m: 0.8399 - val_loss: 0.3526 - val_acc: 0.8474 - val_f1_m: 0.8474\n",
      "Epoch 37/170\n",
      "284/284 - 0s - loss: 0.3502 - acc: 0.8485 - f1_m: 0.8485 - val_loss: 0.3556 - val_acc: 0.8430 - val_f1_m: 0.8424\n",
      "Epoch 38/170\n",
      "284/284 - 0s - loss: 0.3475 - acc: 0.8459 - f1_m: 0.8459 - val_loss: 0.3449 - val_acc: 0.8466 - val_f1_m: 0.8459\n",
      "Epoch 39/170\n",
      "284/284 - 0s - loss: 0.3463 - acc: 0.8492 - f1_m: 0.8502 - val_loss: 0.3439 - val_acc: 0.8519 - val_f1_m: 0.8513\n",
      "Epoch 40/170\n",
      "284/284 - 0s - loss: 0.3470 - acc: 0.8505 - f1_m: 0.8515 - val_loss: 0.3448 - val_acc: 0.8554 - val_f1_m: 0.8556\n",
      "Epoch 41/170\n",
      "284/284 - 0s - loss: 0.3443 - acc: 0.8499 - f1_m: 0.8500 - val_loss: 0.3427 - val_acc: 0.8554 - val_f1_m: 0.8554\n",
      "Epoch 42/170\n",
      "284/284 - 0s - loss: 0.3383 - acc: 0.8527 - f1_m: 0.8529 - val_loss: 0.3401 - val_acc: 0.8589 - val_f1_m: 0.8585\n",
      "Epoch 43/170\n",
      "284/284 - 0s - loss: 0.3421 - acc: 0.8530 - f1_m: 0.8523 - val_loss: 0.3397 - val_acc: 0.8589 - val_f1_m: 0.8585\n",
      "Epoch 44/170\n",
      "284/284 - 0s - loss: 0.3405 - acc: 0.8472 - f1_m: 0.8471 - val_loss: 0.3385 - val_acc: 0.8598 - val_f1_m: 0.8593\n",
      "Epoch 45/170\n",
      "284/284 - 0s - loss: 0.3416 - acc: 0.8532 - f1_m: 0.8536 - val_loss: 0.3377 - val_acc: 0.8616 - val_f1_m: 0.8610\n",
      "Epoch 46/170\n",
      "284/284 - 0s - loss: 0.3371 - acc: 0.8593 - f1_m: 0.8595 - val_loss: 0.3401 - val_acc: 0.8598 - val_f1_m: 0.8584\n",
      "Epoch 47/170\n",
      "284/284 - 0s - loss: 0.3391 - acc: 0.8512 - f1_m: 0.8511 - val_loss: 0.3607 - val_acc: 0.8325 - val_f1_m: 0.8324\n",
      "Epoch 48/170\n",
      "284/284 - 0s - loss: 0.3367 - acc: 0.8527 - f1_m: 0.8526 - val_loss: 0.3441 - val_acc: 0.8598 - val_f1_m: 0.8593\n",
      "Epoch 49/170\n",
      "284/284 - 0s - loss: 0.3348 - acc: 0.8499 - f1_m: 0.8500 - val_loss: 0.3691 - val_acc: 0.8466 - val_f1_m: 0.8467\n",
      "Epoch 50/170\n",
      "284/284 - 0s - loss: 0.3313 - acc: 0.8505 - f1_m: 0.8511 - val_loss: 0.3353 - val_acc: 0.8598 - val_f1_m: 0.8611\n",
      "Epoch 51/170\n",
      "284/284 - 0s - loss: 0.3314 - acc: 0.8556 - f1_m: 0.8560 - val_loss: 0.3340 - val_acc: 0.8616 - val_f1_m: 0.8615\n",
      "Epoch 52/170\n",
      "284/284 - 0s - loss: 0.3302 - acc: 0.8571 - f1_m: 0.8573 - val_loss: 0.3406 - val_acc: 0.8633 - val_f1_m: 0.8632\n",
      "Epoch 53/170\n",
      "284/284 - 0s - loss: 0.3259 - acc: 0.8574 - f1_m: 0.8573 - val_loss: 0.3832 - val_acc: 0.8307 - val_f1_m: 0.8307\n",
      "Epoch 54/170\n",
      "284/284 - 0s - loss: 0.3261 - acc: 0.8600 - f1_m: 0.8601 - val_loss: 0.3352 - val_acc: 0.8624 - val_f1_m: 0.8624\n",
      "Epoch 55/170\n",
      "284/284 - 0s - loss: 0.3245 - acc: 0.8578 - f1_m: 0.8573 - val_loss: 0.4002 - val_acc: 0.8166 - val_f1_m: 0.8165\n",
      "Epoch 56/170\n",
      "284/284 - 0s - loss: 0.3261 - acc: 0.8565 - f1_m: 0.8564 - val_loss: 0.3441 - val_acc: 0.8589 - val_f1_m: 0.8589\n",
      "Epoch 57/170\n",
      "284/284 - 0s - loss: 0.3254 - acc: 0.8587 - f1_m: 0.8580 - val_loss: 0.3371 - val_acc: 0.8651 - val_f1_m: 0.8642\n",
      "Epoch 58/170\n",
      "284/284 - 0s - loss: 0.3225 - acc: 0.8607 - f1_m: 0.8606 - val_loss: 0.3574 - val_acc: 0.8351 - val_f1_m: 0.8359\n",
      "Epoch 59/170\n",
      "284/284 - 0s - loss: 0.3265 - acc: 0.8563 - f1_m: 0.8563 - val_loss: 0.3924 - val_acc: 0.8245 - val_f1_m: 0.8244\n",
      "Epoch 60/170\n",
      "284/284 - 0s - loss: 0.3181 - acc: 0.8611 - f1_m: 0.8621 - val_loss: 0.3321 - val_acc: 0.8668 - val_f1_m: 0.8677\n",
      "Epoch 61/170\n",
      "284/284 - 0s - loss: 0.3220 - acc: 0.8578 - f1_m: 0.8575 - val_loss: 0.3554 - val_acc: 0.8563 - val_f1_m: 0.8557\n",
      "Epoch 62/170\n",
      "284/284 - 0s - loss: 0.3199 - acc: 0.8624 - f1_m: 0.8621 - val_loss: 0.4072 - val_acc: 0.8175 - val_f1_m: 0.8170\n",
      "Epoch 63/170\n",
      "284/284 - 0s - loss: 0.3167 - acc: 0.8638 - f1_m: 0.8639 - val_loss: 0.3432 - val_acc: 0.8474 - val_f1_m: 0.8478\n",
      "Epoch 64/170\n",
      "284/284 - 0s - loss: 0.3156 - acc: 0.8631 - f1_m: 0.8632 - val_loss: 0.4033 - val_acc: 0.8148 - val_f1_m: 0.8147\n",
      "Epoch 65/170\n",
      "284/284 - 0s - loss: 0.3122 - acc: 0.8638 - f1_m: 0.8641 - val_loss: 0.3343 - val_acc: 0.8607 - val_f1_m: 0.8608\n",
      "Epoch 66/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 - 0s - loss: 0.3142 - acc: 0.8618 - f1_m: 0.8626 - val_loss: 0.3369 - val_acc: 0.8651 - val_f1_m: 0.8659\n",
      "Epoch 67/170\n",
      "284/284 - 0s - loss: 0.3142 - acc: 0.8653 - f1_m: 0.8651 - val_loss: 0.3349 - val_acc: 0.8660 - val_f1_m: 0.8658\n",
      "Epoch 68/170\n",
      "284/284 - 0s - loss: 0.3152 - acc: 0.8635 - f1_m: 0.8643 - val_loss: 0.3300 - val_acc: 0.8686 - val_f1_m: 0.8671\n",
      "Epoch 69/170\n",
      "284/284 - 0s - loss: 0.3078 - acc: 0.8679 - f1_m: 0.8676 - val_loss: 0.3641 - val_acc: 0.8545 - val_f1_m: 0.8545\n",
      "Epoch 70/170\n",
      "284/284 - 0s - loss: 0.3033 - acc: 0.8717 - f1_m: 0.8717 - val_loss: 0.3431 - val_acc: 0.8633 - val_f1_m: 0.8642\n",
      "Epoch 71/170\n",
      "284/284 - 0s - loss: 0.3091 - acc: 0.8627 - f1_m: 0.8631 - val_loss: 0.3290 - val_acc: 0.8713 - val_f1_m: 0.8711\n",
      "Epoch 72/170\n",
      "284/284 - 0s - loss: 0.3080 - acc: 0.8664 - f1_m: 0.8664 - val_loss: 0.3586 - val_acc: 0.8536 - val_f1_m: 0.8535\n",
      "Epoch 73/170\n",
      "284/284 - 0s - loss: 0.3048 - acc: 0.8710 - f1_m: 0.8709 - val_loss: 0.3592 - val_acc: 0.8527 - val_f1_m: 0.8539\n",
      "Epoch 74/170\n",
      "284/284 - 0s - loss: 0.3035 - acc: 0.8675 - f1_m: 0.8676 - val_loss: 0.3669 - val_acc: 0.8351 - val_f1_m: 0.8345\n",
      "Epoch 75/170\n",
      "284/284 - 0s - loss: 0.3000 - acc: 0.8693 - f1_m: 0.8694 - val_loss: 0.3315 - val_acc: 0.8668 - val_f1_m: 0.8667\n",
      "Epoch 76/170\n",
      "284/284 - 0s - loss: 0.2988 - acc: 0.8693 - f1_m: 0.8697 - val_loss: 0.3243 - val_acc: 0.8713 - val_f1_m: 0.8712\n",
      "Epoch 77/170\n",
      "284/284 - 0s - loss: 0.3017 - acc: 0.8699 - f1_m: 0.8702 - val_loss: 0.3312 - val_acc: 0.8739 - val_f1_m: 0.8739\n",
      "Epoch 78/170\n",
      "284/284 - 0s - loss: 0.2969 - acc: 0.8717 - f1_m: 0.8709 - val_loss: 0.4692 - val_acc: 0.7989 - val_f1_m: 0.7982\n",
      "Epoch 79/170\n",
      "284/284 - 0s - loss: 0.2978 - acc: 0.8735 - f1_m: 0.8734 - val_loss: 0.3289 - val_acc: 0.8748 - val_f1_m: 0.8742\n",
      "Epoch 80/170\n",
      "284/284 - 0s - loss: 0.2968 - acc: 0.8717 - f1_m: 0.8718 - val_loss: 0.3283 - val_acc: 0.8651 - val_f1_m: 0.8654\n",
      "Epoch 81/170\n",
      "284/284 - 0s - loss: 0.3007 - acc: 0.8664 - f1_m: 0.8666 - val_loss: 0.4031 - val_acc: 0.8316 - val_f1_m: 0.8309\n",
      "Epoch 82/170\n",
      "284/284 - 0s - loss: 0.2912 - acc: 0.8812 - f1_m: 0.8816 - val_loss: 0.3283 - val_acc: 0.8704 - val_f1_m: 0.8703\n",
      "Epoch 83/170\n",
      "284/284 - 0s - loss: 0.2967 - acc: 0.8721 - f1_m: 0.8715 - val_loss: 0.3517 - val_acc: 0.8589 - val_f1_m: 0.8583\n",
      "Epoch 84/170\n",
      "284/284 - 0s - loss: 0.2906 - acc: 0.8748 - f1_m: 0.8751 - val_loss: 0.3273 - val_acc: 0.8721 - val_f1_m: 0.8721\n",
      "Epoch 85/170\n",
      "284/284 - 0s - loss: 0.2922 - acc: 0.8728 - f1_m: 0.8725 - val_loss: 0.3291 - val_acc: 0.8713 - val_f1_m: 0.8718\n",
      "Epoch 86/170\n",
      "284/284 - 0s - loss: 0.2898 - acc: 0.8757 - f1_m: 0.8756 - val_loss: 0.3242 - val_acc: 0.8739 - val_f1_m: 0.8735\n",
      "Epoch 87/170\n",
      "284/284 - 0s - loss: 0.2902 - acc: 0.8748 - f1_m: 0.8749 - val_loss: 0.3220 - val_acc: 0.8757 - val_f1_m: 0.8756\n",
      "Epoch 88/170\n",
      "284/284 - 0s - loss: 0.2846 - acc: 0.8781 - f1_m: 0.8780 - val_loss: 0.3447 - val_acc: 0.8616 - val_f1_m: 0.8610\n",
      "Epoch 89/170\n",
      "284/284 - 0s - loss: 0.2836 - acc: 0.8796 - f1_m: 0.8798 - val_loss: 0.3503 - val_acc: 0.8519 - val_f1_m: 0.8514\n",
      "Epoch 90/170\n",
      "284/284 - 0s - loss: 0.2813 - acc: 0.8836 - f1_m: 0.8837 - val_loss: 0.3598 - val_acc: 0.8545 - val_f1_m: 0.8544\n",
      "Epoch 91/170\n",
      "284/284 - 0s - loss: 0.2773 - acc: 0.8812 - f1_m: 0.8816 - val_loss: 0.3428 - val_acc: 0.8660 - val_f1_m: 0.8654\n",
      "Epoch 92/170\n",
      "284/284 - 0s - loss: 0.2812 - acc: 0.8832 - f1_m: 0.8833 - val_loss: 0.3284 - val_acc: 0.8642 - val_f1_m: 0.8642\n",
      "Epoch 93/170\n",
      "284/284 - 0s - loss: 0.2764 - acc: 0.8836 - f1_m: 0.8836 - val_loss: 0.3713 - val_acc: 0.8413 - val_f1_m: 0.8413\n",
      "Epoch 94/170\n",
      "284/284 - 0s - loss: 0.2794 - acc: 0.8783 - f1_m: 0.8781 - val_loss: 0.3730 - val_acc: 0.8316 - val_f1_m: 0.8335\n",
      "Epoch 95/170\n",
      "284/284 - 0s - loss: 0.2725 - acc: 0.8843 - f1_m: 0.8844 - val_loss: 0.3275 - val_acc: 0.8774 - val_f1_m: 0.8778\n",
      "Epoch 96/170\n",
      "284/284 - 0s - loss: 0.2736 - acc: 0.8858 - f1_m: 0.8855 - val_loss: 0.5220 - val_acc: 0.7866 - val_f1_m: 0.7865\n",
      "Epoch 97/170\n",
      "284/284 - 0s - loss: 0.2689 - acc: 0.8812 - f1_m: 0.8811 - val_loss: 0.3898 - val_acc: 0.8210 - val_f1_m: 0.8196\n",
      "Epoch 98/170\n",
      "284/284 - 0s - loss: 0.2678 - acc: 0.8860 - f1_m: 0.8864 - val_loss: 0.3665 - val_acc: 0.8439 - val_f1_m: 0.8434\n",
      "Epoch 99/170\n",
      "284/284 - 0s - loss: 0.2643 - acc: 0.8887 - f1_m: 0.8885 - val_loss: 0.3324 - val_acc: 0.8713 - val_f1_m: 0.8719\n",
      "Epoch 100/170\n",
      "284/284 - 0s - loss: 0.2664 - acc: 0.8931 - f1_m: 0.8926 - val_loss: 0.3342 - val_acc: 0.8668 - val_f1_m: 0.8673\n",
      "Epoch 101/170\n",
      "284/284 - 0s - loss: 0.2603 - acc: 0.8931 - f1_m: 0.8930 - val_loss: 0.3296 - val_acc: 0.8695 - val_f1_m: 0.8695\n",
      "Epoch 102/170\n",
      "284/284 - 0s - loss: 0.2566 - acc: 0.8951 - f1_m: 0.8951 - val_loss: 0.3796 - val_acc: 0.8316 - val_f1_m: 0.8311\n",
      "Epoch 103/170\n",
      "284/284 - 0s - loss: 0.2617 - acc: 0.8902 - f1_m: 0.8906 - val_loss: 0.3845 - val_acc: 0.8333 - val_f1_m: 0.8334\n",
      "Epoch 104/170\n",
      "284/284 - 0s - loss: 0.2586 - acc: 0.8929 - f1_m: 0.8930 - val_loss: 0.3234 - val_acc: 0.8695 - val_f1_m: 0.8695\n",
      "Epoch 105/170\n",
      "284/284 - 0s - loss: 0.2491 - acc: 0.8979 - f1_m: 0.8975 - val_loss: 0.4207 - val_acc: 0.8042 - val_f1_m: 0.8035\n",
      "Epoch 106/170\n",
      "284/284 - 0s - loss: 0.2507 - acc: 0.8946 - f1_m: 0.8948 - val_loss: 0.3568 - val_acc: 0.8624 - val_f1_m: 0.8624\n",
      "Epoch 107/170\n",
      "284/284 - 0s - loss: 0.2496 - acc: 0.8975 - f1_m: 0.8974 - val_loss: 0.3656 - val_acc: 0.8554 - val_f1_m: 0.8549\n",
      "Epoch 108/170\n",
      "284/284 - 0s - loss: 0.2493 - acc: 0.8946 - f1_m: 0.8944 - val_loss: 0.3286 - val_acc: 0.8677 - val_f1_m: 0.8686\n",
      "Epoch 109/170\n",
      "284/284 - 0s - loss: 0.2471 - acc: 0.8968 - f1_m: 0.8968 - val_loss: 0.3412 - val_acc: 0.8624 - val_f1_m: 0.8634\n",
      "Epoch 110/170\n",
      "284/284 - 0s - loss: 0.2493 - acc: 0.8959 - f1_m: 0.8965 - val_loss: 0.4837 - val_acc: 0.7866 - val_f1_m: 0.7863\n",
      "Epoch 111/170\n",
      "284/284 - 0s - loss: 0.2430 - acc: 0.8999 - f1_m: 0.8999 - val_loss: 0.4054 - val_acc: 0.8386 - val_f1_m: 0.8387\n",
      "Epoch 112/170\n",
      "284/284 - 0s - loss: 0.2440 - acc: 0.9015 - f1_m: 0.9017 - val_loss: 0.3173 - val_acc: 0.8827 - val_f1_m: 0.8826\n",
      "Epoch 113/170\n",
      "284/284 - 0s - loss: 0.2475 - acc: 0.8968 - f1_m: 0.8969 - val_loss: 0.3510 - val_acc: 0.8474 - val_f1_m: 0.8475\n",
      "Epoch 114/170\n",
      "284/284 - 0s - loss: 0.2359 - acc: 0.9023 - f1_m: 0.9023 - val_loss: 0.3384 - val_acc: 0.8571 - val_f1_m: 0.8576\n",
      "Epoch 115/170\n",
      "284/284 - 0s - loss: 0.2358 - acc: 0.9019 - f1_m: 0.9019 - val_loss: 0.3201 - val_acc: 0.8818 - val_f1_m: 0.8820\n",
      "Epoch 116/170\n",
      "284/284 - 0s - loss: 0.2277 - acc: 0.9072 - f1_m: 0.9070 - val_loss: 0.3294 - val_acc: 0.8721 - val_f1_m: 0.8730\n",
      "Epoch 117/170\n",
      "284/284 - 0s - loss: 0.2317 - acc: 0.9085 - f1_m: 0.9084 - val_loss: 0.3485 - val_acc: 0.8501 - val_f1_m: 0.8504\n",
      "Epoch 118/170\n",
      "284/284 - 0s - loss: 0.2280 - acc: 0.9094 - f1_m: 0.9094 - val_loss: 0.3284 - val_acc: 0.8730 - val_f1_m: 0.8725\n",
      "Epoch 119/170\n",
      "284/284 - 0s - loss: 0.2259 - acc: 0.9098 - f1_m: 0.9102 - val_loss: 0.3264 - val_acc: 0.8739 - val_f1_m: 0.8739\n",
      "Epoch 120/170\n",
      "284/284 - 0s - loss: 0.2279 - acc: 0.9041 - f1_m: 0.9039 - val_loss: 0.4528 - val_acc: 0.8254 - val_f1_m: 0.8242\n",
      "Epoch 121/170\n",
      "284/284 - 0s - loss: 0.2262 - acc: 0.9076 - f1_m: 0.9073 - val_loss: 0.3760 - val_acc: 0.8651 - val_f1_m: 0.8659\n",
      "Epoch 122/170\n",
      "284/284 - 0s - loss: 0.2269 - acc: 0.9081 - f1_m: 0.9084 - val_loss: 0.4621 - val_acc: 0.8325 - val_f1_m: 0.8324\n",
      "Epoch 123/170\n",
      "284/284 - 0s - loss: 0.2198 - acc: 0.9138 - f1_m: 0.9134 - val_loss: 0.3128 - val_acc: 0.8810 - val_f1_m: 0.8807\n",
      "Epoch 124/170\n",
      "284/284 - 0s - loss: 0.2241 - acc: 0.9127 - f1_m: 0.9127 - val_loss: 0.3349 - val_acc: 0.8783 - val_f1_m: 0.8786\n",
      "Epoch 125/170\n",
      "284/284 - 0s - loss: 0.2223 - acc: 0.9076 - f1_m: 0.9076 - val_loss: 0.5616 - val_acc: 0.7840 - val_f1_m: 0.7840\n",
      "Epoch 126/170\n",
      "284/284 - 0s - loss: 0.2130 - acc: 0.9120 - f1_m: 0.9122 - val_loss: 0.3968 - val_acc: 0.8369 - val_f1_m: 0.8371\n",
      "Epoch 127/170\n",
      "284/284 - 0s - loss: 0.2193 - acc: 0.9076 - f1_m: 0.9079 - val_loss: 0.3215 - val_acc: 0.8783 - val_f1_m: 0.8779\n",
      "Epoch 128/170\n",
      "284/284 - 0s - loss: 0.2087 - acc: 0.9142 - f1_m: 0.9143 - val_loss: 0.3274 - val_acc: 0.8651 - val_f1_m: 0.8644\n",
      "Epoch 129/170\n",
      "284/284 - 0s - loss: 0.2018 - acc: 0.9171 - f1_m: 0.9171 - val_loss: 0.5028 - val_acc: 0.7866 - val_f1_m: 0.7879\n",
      "Epoch 130/170\n",
      "284/284 - 0s - loss: 0.2129 - acc: 0.9129 - f1_m: 0.9128 - val_loss: 0.3281 - val_acc: 0.8845 - val_f1_m: 0.8851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/170\n",
      "284/284 - 0s - loss: 0.2041 - acc: 0.9204 - f1_m: 0.9207 - val_loss: 0.3214 - val_acc: 0.8774 - val_f1_m: 0.8774\n",
      "Epoch 132/170\n",
      "284/284 - 0s - loss: 0.2078 - acc: 0.9217 - f1_m: 0.9220 - val_loss: 0.3201 - val_acc: 0.8810 - val_f1_m: 0.8803\n",
      "Epoch 133/170\n",
      "284/284 - 0s - loss: 0.1990 - acc: 0.9235 - f1_m: 0.9230 - val_loss: 0.3258 - val_acc: 0.8783 - val_f1_m: 0.8787\n",
      "Epoch 134/170\n",
      "284/284 - 0s - loss: 0.1952 - acc: 0.9239 - f1_m: 0.9242 - val_loss: 0.3513 - val_acc: 0.8765 - val_f1_m: 0.8770\n",
      "Epoch 135/170\n",
      "284/284 - 0s - loss: 0.2010 - acc: 0.9224 - f1_m: 0.9225 - val_loss: 0.3331 - val_acc: 0.8721 - val_f1_m: 0.8721\n",
      "Epoch 136/170\n",
      "284/284 - 0s - loss: 0.1900 - acc: 0.9292 - f1_m: 0.9294 - val_loss: 0.4323 - val_acc: 0.8210 - val_f1_m: 0.8206\n",
      "Epoch 137/170\n",
      "284/284 - 0s - loss: 0.2006 - acc: 0.9198 - f1_m: 0.9202 - val_loss: 0.3358 - val_acc: 0.8836 - val_f1_m: 0.8838\n",
      "Epoch 138/170\n",
      "284/284 - 0s - loss: 0.1959 - acc: 0.9242 - f1_m: 0.9242 - val_loss: 0.3144 - val_acc: 0.8783 - val_f1_m: 0.8791\n",
      "Epoch 139/170\n",
      "284/284 - 0s - loss: 0.1927 - acc: 0.9220 - f1_m: 0.9220 - val_loss: 0.3464 - val_acc: 0.8589 - val_f1_m: 0.8585\n",
      "Epoch 140/170\n",
      "284/284 - 0s - loss: 0.1850 - acc: 0.9268 - f1_m: 0.9270 - val_loss: 0.3360 - val_acc: 0.8827 - val_f1_m: 0.8828\n",
      "Epoch 141/170\n",
      "284/284 - 0s - loss: 0.1878 - acc: 0.9270 - f1_m: 0.9270 - val_loss: 0.3998 - val_acc: 0.8607 - val_f1_m: 0.8606\n",
      "Epoch 142/170\n",
      "284/284 - 0s - loss: 0.1939 - acc: 0.9228 - f1_m: 0.9226 - val_loss: 0.3617 - val_acc: 0.8668 - val_f1_m: 0.8671\n",
      "Epoch 143/170\n",
      "284/284 - 0s - loss: 0.1895 - acc: 0.9246 - f1_m: 0.9247 - val_loss: 0.3235 - val_acc: 0.8774 - val_f1_m: 0.8779\n",
      "Epoch 144/170\n",
      "284/284 - 0s - loss: 0.1823 - acc: 0.9323 - f1_m: 0.9322 - val_loss: 0.3554 - val_acc: 0.8695 - val_f1_m: 0.8688\n",
      "Epoch 145/170\n",
      "284/284 - 0s - loss: 0.1828 - acc: 0.9261 - f1_m: 0.9260 - val_loss: 0.3614 - val_acc: 0.8695 - val_f1_m: 0.8695\n",
      "Epoch 146/170\n",
      "284/284 - 0s - loss: 0.1854 - acc: 0.9272 - f1_m: 0.9272 - val_loss: 0.3332 - val_acc: 0.8774 - val_f1_m: 0.8767\n",
      "Epoch 147/170\n",
      "284/284 - 0s - loss: 0.1731 - acc: 0.9292 - f1_m: 0.9291 - val_loss: 0.3560 - val_acc: 0.8765 - val_f1_m: 0.8766\n",
      "Epoch 148/170\n",
      "284/284 - 0s - loss: 0.1703 - acc: 0.9354 - f1_m: 0.9351 - val_loss: 0.3281 - val_acc: 0.8721 - val_f1_m: 0.8721\n",
      "Epoch 149/170\n",
      "284/284 - 0s - loss: 0.1820 - acc: 0.9301 - f1_m: 0.9300 - val_loss: 0.3563 - val_acc: 0.8810 - val_f1_m: 0.8810\n",
      "Epoch 150/170\n",
      "284/284 - 0s - loss: 0.1687 - acc: 0.9308 - f1_m: 0.9311 - val_loss: 0.3542 - val_acc: 0.8563 - val_f1_m: 0.8561\n",
      "Epoch 151/170\n",
      "284/284 - 0s - loss: 0.1682 - acc: 0.9361 - f1_m: 0.9362 - val_loss: 0.3356 - val_acc: 0.8721 - val_f1_m: 0.8726\n",
      "Epoch 152/170\n",
      "284/284 - 0s - loss: 0.1758 - acc: 0.9328 - f1_m: 0.9327 - val_loss: 0.3427 - val_acc: 0.8783 - val_f1_m: 0.8792\n",
      "Epoch 153/170\n",
      "284/284 - 0s - loss: 0.1702 - acc: 0.9328 - f1_m: 0.9328 - val_loss: 0.3638 - val_acc: 0.8810 - val_f1_m: 0.8806\n",
      "Epoch 154/170\n",
      "284/284 - 0s - loss: 0.1660 - acc: 0.9317 - f1_m: 0.9320 - val_loss: 0.3385 - val_acc: 0.8624 - val_f1_m: 0.8626\n",
      "Epoch 155/170\n",
      "284/284 - 0s - loss: 0.1649 - acc: 0.9374 - f1_m: 0.9372 - val_loss: 0.3252 - val_acc: 0.8854 - val_f1_m: 0.8854\n",
      "Epoch 156/170\n",
      "284/284 - 0s - loss: 0.1601 - acc: 0.9372 - f1_m: 0.9373 - val_loss: 0.3269 - val_acc: 0.8818 - val_f1_m: 0.8814\n",
      "Epoch 157/170\n",
      "284/284 - 0s - loss: 0.1625 - acc: 0.9363 - f1_m: 0.9364 - val_loss: 0.4248 - val_acc: 0.8713 - val_f1_m: 0.8714\n",
      "Epoch 158/170\n",
      "284/284 - 0s - loss: 0.1628 - acc: 0.9352 - f1_m: 0.9354 - val_loss: 0.3472 - val_acc: 0.8713 - val_f1_m: 0.8706\n",
      "Epoch 159/170\n",
      "284/284 - 0s - loss: 0.1482 - acc: 0.9462 - f1_m: 0.9465 - val_loss: 0.3280 - val_acc: 0.8854 - val_f1_m: 0.8854\n",
      "Epoch 160/170\n",
      "284/284 - 0s - loss: 0.1522 - acc: 0.9427 - f1_m: 0.9428 - val_loss: 0.3668 - val_acc: 0.8616 - val_f1_m: 0.8615\n",
      "Epoch 161/170\n",
      "284/284 - 0s - loss: 0.1488 - acc: 0.9460 - f1_m: 0.9463 - val_loss: 0.3427 - val_acc: 0.8818 - val_f1_m: 0.8819\n",
      "Epoch 162/170\n",
      "284/284 - 0s - loss: 0.1473 - acc: 0.9449 - f1_m: 0.9450 - val_loss: 0.3567 - val_acc: 0.8774 - val_f1_m: 0.8776\n",
      "Epoch 163/170\n",
      "284/284 - 0s - loss: 0.1497 - acc: 0.9420 - f1_m: 0.9416 - val_loss: 0.3831 - val_acc: 0.8474 - val_f1_m: 0.8473\n",
      "Epoch 164/170\n",
      "284/284 - 0s - loss: 0.1525 - acc: 0.9394 - f1_m: 0.9397 - val_loss: 0.3486 - val_acc: 0.8810 - val_f1_m: 0.8812\n",
      "Epoch 165/170\n",
      "284/284 - 0s - loss: 0.1436 - acc: 0.9493 - f1_m: 0.9491 - val_loss: 0.3584 - val_acc: 0.8686 - val_f1_m: 0.8687\n",
      "Epoch 166/170\n",
      "284/284 - 0s - loss: 0.1511 - acc: 0.9427 - f1_m: 0.9427 - val_loss: 0.3342 - val_acc: 0.8818 - val_f1_m: 0.8824\n",
      "Epoch 167/170\n",
      "284/284 - 0s - loss: 0.1364 - acc: 0.9491 - f1_m: 0.9494 - val_loss: 0.3416 - val_acc: 0.8801 - val_f1_m: 0.8800\n",
      "Epoch 168/170\n",
      "284/284 - 0s - loss: 0.1364 - acc: 0.9526 - f1_m: 0.9526 - val_loss: 0.4001 - val_acc: 0.8536 - val_f1_m: 0.8546\n",
      "Epoch 169/170\n",
      "284/284 - 0s - loss: 0.1541 - acc: 0.9422 - f1_m: 0.9422 - val_loss: 0.3310 - val_acc: 0.8854 - val_f1_m: 0.8853\n",
      "Epoch 170/170\n",
      "284/284 - 0s - loss: 0.1268 - acc: 0.9544 - f1_m: 0.9543 - val_loss: 0.3513 - val_acc: 0.8765 - val_f1_m: 0.8761\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=16, epochs=170, verbose=2,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.5185 - acc: 0.8793 - f1_m: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5185034275054932, 0.8793103694915771, 0.8798075914382935]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-8f3136b79f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/ayush/Documents/personal/research/aaai/hostility_classification/data/Constraint_Hindi_Valid - Sheet1.csv\"\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making labels\n",
    "from keras.utils import to_categorical\n",
    "y = []\n",
    "label_mapping = {'non-hostile':0, 'hate':1,'offensive':1,'fake':1,'defamation':1}\n",
    "for labels in data['Labels Set']:\n",
    "    temp = list(set([str(i)for i in [label_mapping[x] for x in labels.split(',')]]))\n",
    "    temp = \" \".join(temp)\n",
    "    #print(temp)\n",
    "    y.append(temp)\n",
    "y = [int(x) for x in y]\n",
    "y = to_categorical(y)\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets= []\n",
    "for tweet in data['Post']:\n",
    "    all_tweets.append(feature_analysis(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = []\n",
    "for tweet in all_tweets:\n",
    "    X_text.append(ft.get_sentence_vector(tweet[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=X_text)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(df, y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# #pca=PCA(n_components=50)\n",
    "\n",
    "# X=pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "personal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
